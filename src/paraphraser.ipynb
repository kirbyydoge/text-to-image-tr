{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_paraphrase(model, tokenizer, text):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model.generate(input_ids)\n",
    "    return(tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
    "\n",
    "def k_hop_path(source, targets, k, chain=None, replacement=False):\n",
    "    if chain:\n",
    "        return [source] + chain + (random.choices(targets, k=k-len(chain)) if replacement else random.sample(targets, k=k-len(chain))) + [source]\n",
    "    else:\n",
    "        return [source] + (random.choices(targets, k=k) if replacement else random.sample(targets, k=k)) + [source]\n",
    "\n",
    "def path_translate(translator, path, text):\n",
    "    for i in range(len(path)-1):\n",
    "        text = translator.translate(text, src=path[i], dest=path[i+1]).text\n",
    "    return text\n",
    "\n",
    "def k_hop_paraphrase(translator, source, targets, k, text, chain=None, replacement=False):\n",
    "    return path_translate(translator, k_hop_path(source, targets, k, chain=chain, replacement=replacement), text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: son model arabalar çevreye daha mı az zarar veriyor?\n",
      "Bert: son model arabalar çevre için daha az zararlı mı?\n",
      "K-Hop_3: En son model arabalar çevreye zarar verdi mi?\n",
      "K-Hop_5: En son otomobillere çevreye zarar verdi mi?\n",
      "K-Hop_7: Çevrenin en son otomobilleri hasar gördü mü?\n",
      "\n",
      "Original: çürük raporu alırsam iş bulmada sıkıntı yaşar mıyım?\n",
      "Bert: çürük raporu alırsam iş bulamaz mıyım?\n",
      "K-Hop_3: Çürümüş raporu alırsam, bir iş bulmak zor mu?\n",
      "K-Hop_5: Tembel bir rapor alırsam, bir iş bulmak zor mu?\n",
      "K-Hop_7: Çürük ilişkiyi alırsam iş bulmak zor buldum?\n",
      "\n",
      "Original: ingilizce yazma yeteneğimi geliştirmenin en iyi yolu nedir?\n",
      "Bert: ingilizce yazma becerilerimi nasıl geliştirebilirim?\n",
      "K-Hop_3: İngilizce yazma yeteneğimi geliştirmenin en iyi yolu nedir?\n",
      "K-Hop_5: İngilizce yazma yeteneğimi geliştirmenin en iyi yolu nedir?\n",
      "K-Hop_7: İngilizce yazımımı geliştirmenin en iyi yolu nedir?\n",
      "\n",
      "Original: şimdiye kadarki en iyi şaka nedir? niye ya?\n",
      "Bert: şimdiye kadar duyduğun en iyi şaka nedir?\n",
      "K-Hop_3: Şimdiye kadarki en iyi şaka nedir? Neden?\n",
      "K-Hop_5: En iyi şaka nedir? Neden?\n",
      "K-Hop_7: Her zaman en iyi şaka nedir?Çünkü?\n",
      "\n",
      "Original: yüksek bir ıq'nun bazı olumsuz etkileri nelerdir?\n",
      "Bert: yüksek ıq'nun olumsuz etkileri nelerdir?\n",
      "K-Hop_3: Yüksek IQ'nun birkaç olumsuz etkisi nedir?\n",
      "K-Hop_5: Yüksek qi'nin olumsuz etkisi nedir?\n",
      "K-Hop_7: Yüksek IQ'nin olumsuz etkileri nelerdir?\n",
      "\n",
      "Original: tüm zamanların en iyi 10 kitabı hangileridir?\n",
      "Bert: tüm zamanların en iyi 10 kitabı hangileridir?\n",
      "K-Hop_3: Tüm zamanların en iyi 10 kitabı nelerdir?\n",
      "K-Hop_5: En iyi on kitap hangileridir?\n",
      "K-Hop_7: En iyi on en iyi kitap hangileridir?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "model = EncoderDecoderModel.from_pretrained(\"ahmetbagci/bert2bert-turkish-paraphrase-generation\")\n",
    "\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source = \"tr\"\n",
    "targets = [\"en\", \"de\", \"es\", \"sv\", \"ru\", \"hu\", \"it\", \"fr\"]\n",
    "chain = [\"en\"]\n",
    "replacement = False\n",
    "\n",
    "sentences = [\n",
    "    \"son model arabalar çevreye daha mı az zarar veriyor?\",\n",
    "    \"çürük raporu alırsam iş bulmada sıkıntı yaşar mıyım?\",\n",
    "    \"ingilizce yazma yeteneğimi geliştirmenin en iyi yolu nedir?\",\n",
    "    \"şimdiye kadarki en iyi şaka nedir? niye ya?\",\n",
    "    \"yüksek bir ıq'nun bazı olumsuz etkileri nelerdir?\",\n",
    "    \"tüm zamanların en iyi 10 kitabı hangileridir?\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    bert = bert_paraphrase(model, tokenizer, sentence)\n",
    "    k_hop_3 = k_hop_paraphrase(translator, source, targets, 3, sentence, chain=chain, replacement=replacement)\n",
    "    k_hop_5 = k_hop_paraphrase(translator, source, targets, 5, sentence, chain=chain, replacement=replacement)\n",
    "    k_hop_7 = k_hop_paraphrase(translator, source, targets, 7, sentence, chain=chain, replacement=replacement)\n",
    "    print(f\"Original: {sentence}\\nBert: {bert}\\nK-Hop_3: {k_hop_3}\\nK-Hop_5: {k_hop_5}\\nK-Hop_7: {k_hop_7}\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80375147073dd174b1f42e5188bfd0c04afeb59d297f4ec5ad553b9ba699b15c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
