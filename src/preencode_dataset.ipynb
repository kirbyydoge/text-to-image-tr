{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import yaml\n",
    "import io\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import struct\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "DATA_PATH = \"D:/C12M/cc12m_tr.tsv\"\n",
    "OUT_PATH = \"D:/C12M/cc12m_tr_encoded.bin\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "PRETRAIN_DIR = \"pretrained\"\n",
    "MODEL_DIR = \"vqgan_f16_16384\"\n",
    "NUM_PATCHES = 256\n",
    "NUM_DOWNLOADERS = 15\n",
    "NUM_PREENCODERS = 1\n",
    "INFO_FREQ = 50\n",
    "\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "    config = OmegaConf.load(config_path)\n",
    "    if display:\n",
    "        print(yaml.dump(OmegaConf.to_container(config)))\n",
    "    return config\n",
    "\n",
    "def load_vqgan(config, ckpt_path=None, is_gumbel=False):\n",
    "    model = VQModel(**config.model.params)\n",
    "    if ckpt_path is not None:\n",
    "        sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "        missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "    return model.eval()\n",
    "\n",
    "def preprocess_vqgan(x):\n",
    "    x = 2.*x - 1.\n",
    "    return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "    x = x.detach().cpu()\n",
    "    x = torch.clamp(x, -1., 1.)\n",
    "    x = (x + 1.)/2.\n",
    "    x = x.permute(1,2,0).numpy()\n",
    "    x = (255*x).astype(np.uint8)\n",
    "    x = Image.fromarray(x)\n",
    "    if not x.mode == \"RGB\":\n",
    "        x = x.convert(\"RGB\")\n",
    "    return x\n",
    "\n",
    "def vqgan_encode(x, model):\n",
    "    with torch.no_grad():\n",
    "        z, _, [_, _, indices] = model.encode(x)\n",
    "        return z, indices\n",
    "\n",
    "def vqgan_decode(x, model):\n",
    "    with torch.no_grad():\n",
    "        return model.decode(x)\n",
    "\n",
    "def vqgan_reconstruct(x, model):\n",
    "    with torch.no_grad():\n",
    "        z, _, [_, _, indices] = model.encode(x)\n",
    "        xrec = model.decode(z)\n",
    "        return xrec\n",
    "\n",
    "def download_image(url, headers=HEADERS):\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    return Image.open(io.BytesIO(resp.content))\n",
    "\n",
    "def preprocess(img, target_image_size=256):\n",
    "    s = min(img.size)\n",
    "    r = target_image_size / s\n",
    "    s = (round(r * img.size[1]), round(r * img.size[0]))\n",
    "    img = TF.resize(img, s, interpolation=Image.LANCZOS)\n",
    "    img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
    "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencode(data_path, out_path, num_patches, device=\"cpu\", max_writes=-1, info_rate=100, verbose=False):\n",
    "\tcfg_vqgan = load_config(f\"../{PRETRAIN_DIR}/{MODEL_DIR}/configs/model.yaml\", display=False)\n",
    "\tmodel_vqgan = load_vqgan(cfg_vqgan, ckpt_path=f\"../{PRETRAIN_DIR}/{MODEL_DIR}/checkpoints/last.ckpt\").to(DEVICE)\n",
    "\tmodel_vqgan.eval()\n",
    "\twith open(data_path, \"r\", encoding=\"utf-8\") as src, open(out_path, \"wb\") as dest:\n",
    "\t\tdest.write(struct.pack(\"i\", num_patches))\n",
    "\t\tnum_writes = 0\n",
    "\t\tline_index = 0\n",
    "\t\tfor line in src:\n",
    "\t\t\tif num_writes == max_writes:\n",
    "\t\t\t\tbreak\n",
    "\t\t\turl, en, tr = line.strip().split(\"\\t\")\n",
    "\t\t\ttry:\n",
    "\t\t\t\timage = preprocess(download_image(url), num_patches).to(device)\n",
    "\t\t\t\twith torch.no_grad():\n",
    "\t\t\t\t\t_, image_tokens = vqgan_encode(image, model_vqgan)\n",
    "\t\t\t\timage_tokens = image_tokens.flatten().type(torch.int32)\n",
    "\t\t\t\tassert len(image_tokens) == num_patches\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint(image_tokens)\n",
    "\t\t\t\tdest.write(struct.pack(\"i\", line_index))\n",
    "\t\t\t\tfor i in range(num_patches):\n",
    "\t\t\t\t\tdest.write(struct.pack(\"i\", image_tokens[i]))\n",
    "\t\t\t\tnum_writes += 1\n",
    "\t\t\t\tif num_writes % info_rate == 0:\n",
    "\t\t\t\t\tprint(f\"INFO: Total lines encoded - {num_writes}.\")\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"ERR: {e} at line {line_index}\")\n",
    "\t\t\tline_index += 1\n",
    "\n",
    "def load_tensor(f, patches):\n",
    "\tidx_bytes = f.read(4)\n",
    "\tif not idx_bytes:\n",
    "\t\treturn -1, None\n",
    "\tindex = struct.unpack(\"i\", idx_bytes)\n",
    "\tdata = torch.zeros(patches, dtype=torch.int32)\n",
    "\tfor i in range(patches):\n",
    "\t\tdata[i] = struct.unpack(\"i\", f.read(4))[0]\n",
    "\treturn index, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_scheduler(data_path, url_queue:Queue):\n",
    "\twith open(data_path, \"r\", encoding=\"utf-8\") as src:\n",
    "\t\tline_index = 0\n",
    "\t\tfor line in src:\n",
    "\t\t\turl, _, _ = line.strip().split(\"\\t\")\n",
    "\t\t\turl_queue.put((line_index, url))\n",
    "\t\t\tline_index += 1\n",
    "\t\turl_queue.put(None)\n",
    "\n",
    "def download_worker(url_queue:Queue, image_queue:Queue, worker_id):\n",
    "\trunning = True\n",
    "\twhile running:\n",
    "\t\ttask = url_queue.get()\n",
    "\t\tif task is None:\n",
    "\t\t\turl_queue.put(None)\n",
    "\t\t\trunning = False\n",
    "\t\t\tbreak\n",
    "\t\ttry:\n",
    "\t\t\tidx = task[0]\n",
    "\t\t\turl = task[1]\n",
    "\t\t\timg = download_image(url)\n",
    "\t\t\timage_queue.put((idx, img))\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "def preencode_worker(image_queue:Queue, token_queue:Queue, worker_id, num_patches, device, info_freq, wait_thresh):\n",
    "\ttime.sleep(worker_id * 3.5) # delay so models are not loaded in parallel\n",
    "\tcfg_vqgan = load_config(f\"../{PRETRAIN_DIR}/{MODEL_DIR}/configs/model.yaml\", display=False)\n",
    "\tmodel_vqgan = load_vqgan(cfg_vqgan, ckpt_path=f\"../{PRETRAIN_DIR}/{MODEL_DIR}/checkpoints/last.ckpt\").to(DEVICE)\n",
    "\tmodel_vqgan.eval()\n",
    "\trunning = True\n",
    "\twaiting_time = 0\n",
    "\tprocess_time = 0\n",
    "\tprofile_count = 0\n",
    "\tfallback = 1\n",
    "\twhile running:\n",
    "\t\twait_start = time.time()\n",
    "\t\ttask = image_queue.get()\n",
    "\t\twait_end = time.time()\n",
    "\t\twaiting_time += wait_end - wait_start\n",
    "\t\tif task is None:\n",
    "\t\t\timage_queue.put(None)\n",
    "\t\t\ttoken_queue.put(None)\n",
    "\t\t\trunning = False\n",
    "\t\t\tbreak\n",
    "\t\tprocess_start = time.time()\n",
    "\t\tidx = task[0]\n",
    "\t\ttry:\n",
    "\t\t\timg = preprocess(task[1], num_patches).to(device)\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\t_, tokens = vqgan_encode(img, model_vqgan)\n",
    "\t\t\ttokens = tokens.flatten().type(torch.int32).to(\"cpu\")\n",
    "\t\t\ttoken_queue.put((idx, tokens))\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass\n",
    "\t\tprocess_end = time.time()\n",
    "\t\tprocess_time += process_end - process_start\n",
    "\t\tprofile_count += 1\n",
    "\t\tif profile_count == info_freq:\n",
    "\t\t\tavg_wait = waiting_time / info_freq\n",
    "\t\t\tavg_proc = process_time / info_freq\n",
    "\t\t\tprint(f\"ENCODER-{worker_id}: AVG Wait - {avg_wait} AVG Process - {avg_proc}\")\n",
    "\t\t\twaiting_time = 0\n",
    "\t\t\tprocess_time = 0\n",
    "\t\t\tprofile_count = 0\n",
    "\t\t\tif worker_id > 0 and avg_wait > avg_proc: # Too many workers\n",
    "\t\t\t\tsleep_amt = worker_id * fallback * 15\n",
    "\t\t\t\tprint(f\"ENCODER-{worker_id}: AVG Wait > AVG Process. Sleeping for {sleep_amt} with fallback {fallback}.\")\n",
    "\t\t\t\ttime.sleep(sleep_amt)\n",
    "\t\t\t\tfallback += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tfallback = max(1, fallback - 1)\n",
    "\n",
    "def token_combiner(out_path, token_queue:Queue, num_patches, num_preencoders, info_freq):\n",
    "\trunning = True\n",
    "\tretired_preencoders = 0\n",
    "\twritten_lines = 0\n",
    "\tfile = open(out_path, \"wb\")\n",
    "\tfile.write(struct.pack(\"i\", num_patches))\n",
    "\tstart = time.time()\n",
    "\twhile running:\n",
    "\t\ttask = token_queue.get()\n",
    "\t\tif task is None:\n",
    "\t\t\tretired_preencoders += 1\n",
    "\t\t\trunning = retired_preencoders < num_preencoders\n",
    "\t\t\tcontinue\n",
    "\t\tidx = task[0]\n",
    "\t\ttokens = task[1]\n",
    "\t\tif file.closed:\n",
    "\t\t\tfile = open(out_path, \"ab\")\n",
    "\t\ttry:\n",
    "\t\t\tassert len(tokens) == num_patches\n",
    "\t\t\tfile.write(struct.pack(\"i\", idx))\n",
    "\t\t\tfile.write(struct.pack(f\"{num_patches}i\", *tokens))\n",
    "\t\t\twritten_lines += 1\n",
    "\t\t\tif written_lines % info_freq == 0:\n",
    "\t\t\t\tprint(f\"COMBINER: Encoded {written_lines} images. EPS: {info_freq / (time.time() - start)}\")\n",
    "\t\t\t\tstart = time.time()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"COMBINER: {e}\")\n",
    "\tfile.flush()\n",
    "\tfile.close()\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pipelined():\n",
    "\turl_queue = Queue()\n",
    "\timage_queue = Queue()\n",
    "\ttoken_queue = Queue()\n",
    "\tscheduler = Thread(target=download_scheduler, args=(DATA_PATH, url_queue))\n",
    "\tdownloaders = []\n",
    "\tpreencoders = []\n",
    "\tfor i in range(NUM_DOWNLOADERS):\n",
    "\t\tthread = Thread(target=download_worker, args=(url_queue, image_queue, i))\n",
    "\t\tdownloaders.append(thread)\n",
    "\tfor i in range(NUM_PREENCODERS):\n",
    "\t\tthread = Thread(target=preencode_worker, args=(image_queue, token_queue, i, NUM_PATCHES, DEVICE, INFO_FREQ, 0.5))\n",
    "\t\tpreencoders.append(thread)\n",
    "\tcombiner = Thread(target=token_combiner, args=(OUT_PATH, token_queue, NUM_PATCHES, NUM_PREENCODERS, INFO_FREQ * NUM_PREENCODERS))\n",
    "\tscheduler.start()\n",
    "\tfor i in range(NUM_DOWNLOADERS):\n",
    "\t\tdownloaders[i].start()\n",
    "\tfor i in range(NUM_PREENCODERS):\n",
    "\t\tpreencoders[i].start()\n",
    "\tcombiner.start()\n",
    "\tscheduler.join()\n",
    "\tprint(\"SCHEDULER: Done\")\n",
    "\tfor i in range(NUM_DOWNLOADERS):\n",
    "\t\tdownloaders[i].join()\n",
    "\t\tprint(f\"DOWNLOADER-{i}: Done\")\n",
    "\tfor i in range(NUM_PREENCODERS):\n",
    "\t\tpreencoders[i].join()\n",
    "\t\tprint(f\"ENCODER-{i}: Done\")\n",
    "\tcombiner.join()\n",
    "\tprint(f\"COMBINER-{i}: Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check():\n",
    "\tpreencode(DATA_PATH, OUT_PATH, NUM_PATCHES, DEVICE, max_writes=1, verbose=True)\n",
    "\tfile = open(OUT_PATH, \"rb\")\n",
    "\tfile.read(4)\n",
    "\tprint(load_tensor(file, NUM_PATCHES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "SCHEDULER: Done\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips\\vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oguzhan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER-0: AVG Wait - 0.00045638084411621095 AVG Process - 0.1200715446472168\n",
      "COMBINER: Encoded 50 images. EPS: 4.625401095437032\n",
      "ENCODER-0: AVG Wait - 0.0003170013427734375 AVG Process - 0.08993515968322754\n",
      "COMBINER: Encoded 100 images. EPS: 11.082502910465468\n",
      "ENCODER-0: AVG Wait - 0.00042668342590332034 AVG Process - 0.08934927463531495\n",
      "COMBINER: Encoded 150 images. EPS: 11.137612730945985\n",
      "ENCODER-0: AVG Wait - 0.00026773929595947266 AVG Process - 0.09678948402404786\n",
      "COMBINER: Encoded 200 images. EPS: 9.933631383831711\n",
      "ENCODER-0: AVG Wait - 0.00037690162658691404 AVG Process - 0.10600512504577636\n",
      "COMBINER: Encoded 250 images. EPS: 9.37821863787871\n",
      "ENCODER-0: AVG Wait - 0.0005341625213623047 AVG Process - 0.11143348217010499\n",
      "COMBINER: Encoded 300 images. EPS: 8.946264829748111\n",
      "ENCODER-0: AVG Wait - 0.00039630889892578125 AVG Process - 0.09597640037536621\n",
      "COMBINER: Encoded 350 images. EPS: 10.145582180443492\n",
      "ENCODER-0: AVG Wait - 0.0003555917739868164 AVG Process - 0.1031099796295166\n",
      "COMBINER: Encoded 400 images. EPS: 9.625367637609374\n",
      "ENCODER-0: AVG Wait - 0.00043642044067382813 AVG Process - 0.11085601329803467\n",
      "COMBINER: Encoded 450 images. EPS: 9.005402420418324\n"
     ]
    }
   ],
   "source": [
    "encode_pipelined()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "116fc0531d454bbdeaf23f70d07b0d49aee0978cb9b9ebe8756766f8c910747e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
